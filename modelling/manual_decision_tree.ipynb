{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiac-package",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wireless-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-retrieval",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unsigned-nylon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['processed_dep_h0', 'processed_dep_h120', 'processed_dep_h180', 'processed_dep_h30'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "for path in glob.glob(r\"../Data/t_taxi/*.csv\"):\n",
    "    data[path.split('\\\\')[-1].split('.')[0]] = pd.read_csv(path)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-depression",
   "metadata": {},
   "source": [
    "# Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rotary-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "def model_eval(y, y_pred, name=None, file=None, verbose=True, **kwargs):\n",
    "    report = {}\n",
    "    if name:\n",
    "        report['name'] = name\n",
    "        if verbose:\n",
    "            print(name)\n",
    "    \n",
    "    report[\"RMSE\"] = mean_squared_error(y, y_pred, squared=False)\n",
    "    report[\"MAE\"] = mean_absolute_error(y, y_pred)\n",
    "    report[\"% <2 min\"] = sum(abs(y-y_pred) < 2*60)/len(y)*100\n",
    "    report[\"% <5 min\"] = sum(abs(y-y_pred) < 5*60)/len(y)*100\n",
    "    report[\"% <7 min\"] = sum(abs(y-y_pred) < 7*60)/len(y)*100\n",
    "    report[\"time\"] = round(time.time())\n",
    "    \n",
    "    for kwarg in kwargs:\n",
    "        report[kwarg] = kwargs[kwarg]\n",
    "    \n",
    "    if file is not None:\n",
    "        with open(file, \"a\") as f:\n",
    "            f.write(str(report)+\"\\n\")\n",
    "    if verbose:\n",
    "        print(report)\n",
    "    return(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-organic",
   "metadata": {},
   "source": [
    "# Manual Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elder-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "class manual_tree:\n",
    "    \"\"\"\n",
    "    make a manual tree for data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.transformations = []\n",
    "        self.fitted = False\n",
    "        import pandas as pd\n",
    "    \n",
    "    def add_transformation(self, X_col, y_col, **kwargs):\n",
    "        \"\"\"\n",
    "        the X_cols to split along,\n",
    "        the y_col\n",
    "        \n",
    "        optional: name: name of the training column (default equal to X_col)\n",
    "        optional: X_col_train: column names for training\n",
    "        \"\"\"\n",
    "        X_col_train = X_col\n",
    "        name = len(self.transformations)\n",
    "        for kwarg in kwargs:\n",
    "            if kwarg=='X_col_train':\n",
    "                X_col_train = kwargs[kwarg]\n",
    "            if kwarg=='name':\n",
    "                name = name\n",
    "        \n",
    "        self.transformations.append(\n",
    "        \n",
    "        {\n",
    "            'name' : name,\n",
    "            'X_col': X_col, \n",
    "            'y_col': y_col,\n",
    "            'X_col_train': X_col_train, # WIP only store when != X_col\n",
    "        })\n",
    "        \n",
    "        self.fitted = False\n",
    "        \n",
    "    def fit(self, df_train):\n",
    "        self.model = []\n",
    "        for t in self.transformations:\n",
    "            self.model.append((t['name'], \n",
    "                               df_train[t['X_col_train'] + [t['y_col']]].groupby(t['X_col_train']).mean()))            \n",
    "        self.fallback = df_train[t['y_col']].mean()\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self, df):\n",
    "        if self.fitted:\n",
    "            y = pd.DataFrame(df.index).set_index(0)\n",
    "            y['y'] = np.nan\n",
    "            for n, m in enumerate(self.model):\n",
    "                filler = pd.merge(df.reset_index(), \n",
    "                                  m[1], \n",
    "                                  how='left', \n",
    "                                  left_on=self.transformations[n]['X_col'], \n",
    "                                  right_on=self.transformations[n]['X_col_train'])\n",
    "                filler = filler.set_index('index')[self.transformations[n]['y_col']+'_y']\n",
    "                y['y'] = y['y'].fillna(filler)\n",
    "            return y['y'].fillna(self.fallback)\n",
    "        else:\n",
    "            raise Exception(\"Model Not Fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aging-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vtt_h0\n",
      "{'name': 'vtt_h0', 'RMSE': 151.37257752428079, 'MAE': 108.3464180114934, '% <2 min': 66.57208056354797, '% <5 min': 95.6344875483679, '% <7 min': 98.5474749479115, 'time': 1618436352, 'dataset_train': 'processed_dep_h0', 'dataset_test': 'processed_dep_h0', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n",
      "vtt_h30\n",
      "{'name': 'vtt_h30', 'RMSE': 152.10289203317856, 'MAE': 109.13842075860204, '% <2 min': 66.2029963290009, '% <5 min': 95.59083242385157, '% <7 min': 98.50183549955352, 'time': 1618436352, 'dataset_train': 'processed_dep_h30', 'dataset_test': 'processed_dep_h0', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n",
      "vtt_h30\n",
      "{'name': 'vtt_h30', 'RMSE': 161.77193253803696, 'MAE': 115.45557620987479, '% <2 min': 64.40519521848957, '% <5 min': 94.3333930027647, '% <7 min': 97.83996658511845, 'time': 1618436353, 'dataset_train': 'processed_dep_h30', 'dataset_test': 'processed_dep_h30', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n",
      "vtt_h30\n",
      "{'name': 'vtt_h30', 'RMSE': 161.77193253803696, 'MAE': 115.45557620987479, '% <2 min': 64.40519521848957, '% <5 min': 94.3333930027647, '% <7 min': 97.83996658511845, 'time': 1618436353, 'dataset_train': 'processed_dep_h30', 'dataset_test': 'processed_dep_h30', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n",
      "vtt_h120\n",
      "{'name': 'vtt_h120', 'RMSE': 204.3688135343004, 'MAE': 150.61685933248484, '% <2 min': 50.911342047576525, '% <5 min': 88.81627019566453, '% <7 min': 95.65843955508646, 'time': 1618436354, 'dataset_train': 'processed_dep_h120', 'dataset_test': 'processed_dep_h120', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n",
      "vtt_h30\n",
      "{'name': 'vtt_h30', 'RMSE': 215.68133699393135, 'MAE': 155.5532444368871, '% <2 min': 52.681253552001294, '% <5 min': 86.18372980433547, '% <7 min': 93.90679548591378, 'time': 1618436354, 'dataset_train': 'processed_dep_h30', 'dataset_test': 'processed_dep_h120', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n",
      "vtt_h180\n",
      "{'name': 'vtt_h180', 'RMSE': 203.5665686626854, 'MAE': 150.0046903477057, '% <2 min': 50.90669698964629, '% <5 min': 88.96403136034472, '% <7 min': 95.52636303788378, 'time': 1618436354, 'dataset_train': 'processed_dep_h180', 'dataset_test': 'processed_dep_h180', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n",
      "vtt_h30\n",
      "{'name': 'vtt_h30', 'RMSE': 212.53535985396474, 'MAE': 153.21231225169913, '% <2 min': 53.22281405230714, '% <5 min': 86.79454186366628, '% <7 min': 94.24561613501706, 'time': 1618436354, 'dataset_train': 'processed_dep_h30', 'dataset_test': 'processed_dep_h180', 'model_type': 'VTT', 'eval_type': 'SIMPLE_TEST'}\n"
     ]
    }
   ],
   "source": [
    "mt_h30 = manual_tree()\n",
    "mt_h30.add_transformation(\n",
    "    X_col = ['depgnr', 'trwy_ext', 'wtc'],\n",
    "    y_col='t_taxi')\n",
    "mt_h30.add_transformation(\n",
    "    X_col = ['trwy_ext', 'wtc'], \n",
    "    y_col='t_taxi')\n",
    "df = data['processed_dep_h30']\n",
    "mt_h30.fit(df[df['dtype'].isin([\"TRAIN\", \"VALIDATE\"])])\n",
    "\n",
    "for h in [0, 30, 120, 180]:\n",
    "    \n",
    "    # This is ugly, apologies!\n",
    "    df = data['processed_dep_h{}'.format(h)]\n",
    "    \n",
    "    X_train = df[df['dtype']==\"TRAIN\"]\n",
    "    X_train.pop(\"dtype\")\n",
    "    y_train = X_train.pop(\"t_taxi\")\n",
    "    \n",
    "    X_val = df[df['dtype']==\"VALIDATE\"]\n",
    "    X_val.pop(\"dtype\")\n",
    "    y_val = X_val.pop(\"t_taxi\")\n",
    "    \n",
    "    X_test = df[df['dtype']==\"TEST\"]\n",
    "    X_test.pop(\"dtype\")\n",
    "    y_test = X_test.pop(\"t_taxi\")\n",
    "    \n",
    "\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "        \n",
    "    mt = manual_tree()\n",
    "\n",
    "    mt.add_transformation(X_col = ['depgnr', 'trwy_ext', 'wtc'],\n",
    "                         y_col='t_taxi')\n",
    "\n",
    "    # Fallback Option When depgnr is Null, barely makes a difference\n",
    "    mt.add_transformation(X_col = ['trwy_ext', 'wtc'], \n",
    "                          y_col='t_taxi') \n",
    "\n",
    "    # MT requires one df, only validation data used for evaluation, no hyperparameter tuning!\n",
    "    df_mt_train = pd.concat([pd.concat([X_train, X_val]), pd.concat([y_train, y_val])], axis=1)\n",
    "    df_mt_test = pd.concat([X_test, y_test], axis=1)\n",
    "    mt.fit(df_mt_train)\n",
    "\n",
    "    y_test_pred_h = mt.predict(df_mt_test)\n",
    "    y_test_pred_h30 = mt_h30.predict(df_mt_test)\n",
    "\n",
    "    model_eval(\n",
    "        y_test, \n",
    "        y_test_pred_h, \n",
    "        name=\"vtt_h{}\".format(h,h), # model, eval technique, params\n",
    "        file=\"./results/model_vtt.results\",\n",
    "        dataset_train=\"processed_dep_h{}\".format(h),\n",
    "        dataset_test=\"processed_dep_h{}\".format(h),\n",
    "        model_type=\"VTT\",\n",
    "        eval_type=\"SIMPLE_TEST\",\n",
    "    )\n",
    "    model_eval(\n",
    "        y_test, \n",
    "        y_test_pred_h30, \n",
    "        name=\"vtt_h30\".format(h,h), # model, eval technique, params\n",
    "        file=\"./results/model_vtt.results\",\n",
    "        dataset_train=\"processed_dep_h30\",\n",
    "        dataset_test=\"processed_dep_h{}\".format(h),\n",
    "        model_type=\"VTT\",\n",
    "        eval_type=\"SIMPLE_TEST\",\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
