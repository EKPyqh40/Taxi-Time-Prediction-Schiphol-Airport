{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda update -y -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115712,
     "status": "ok",
     "timestamp": 1617205324446,
     "user": {
      "displayName": "Christophe Vakaet",
      "photoUrl": "",
      "userId": "01909583539221508445"
     },
     "user_tz": -120
    },
    "id": "bugDHxBakRCR",
    "outputId": "a68648f4-b18a-48e7-bc6f-ba212d542a9c"
   },
   "outputs": [],
   "source": [
    "# !conda install -y numpy scipy scikit-learn pandas joblib pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deap update_checker tqdm stopit xgboost\n",
    "# !pip install dask[delayed] dask[dataframe] dask-ml fsspec>=0.3.3 distributed>=2.10.0\n",
    "# !pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !conda install -y -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install IProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2382,
     "status": "ok",
     "timestamp": 1617205362002,
     "user": {
      "displayName": "Christophe Vakaet",
      "photoUrl": "",
      "userId": "01909583539221508445"
     },
     "user_tz": -120
    },
    "id": "ba4wMOMUemYv",
    "outputId": "5d5e1f64-8bba-45a2-d4dd-4fa19f73b049"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tpot\n",
    "from autosklearn.metrics import mean_absolute_error as auto_sklearn_MAE\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2NzcP1nze1F2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['processed_dep_h0', 'processed_dep_h30', 'processed_dep_h120', 'processed_dep_h180'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "for h in [0, 30, 120, 180]:\n",
    "    data['processed_dep_h{}'.format(h)] = pd.read_csv(\"/mnt/data/Christophe/processed_dep_h{}.csv\".format(h))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/data/Christophe/csv_docs.json\", \"r\") as f:\n",
    "    docs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and Slice Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=30\n",
    "df = data['processed_dep_h{}'.format(h)]\n",
    "\n",
    "X_train = df[df['dtype']==\"TRAIN\"]\n",
    "X_train.pop(\"dtype\")\n",
    "y_train = X_train.pop(\"t_taxi\")\n",
    "\n",
    "X_val = df[df['dtype']==\"VALIDATE\"]\n",
    "X_val.pop(\"dtype\")\n",
    "y_val = X_val.pop(\"t_taxi\")\n",
    "\n",
    "X_test = df[df['dtype']==\"TEST\"]\n",
    "X_test.pop(\"dtype\")\n",
    "y_test = X_test.pop(\"t_taxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "def model_eval(y, y_pred, name=None, file=None, verbose=True, **kwargs):\n",
    "    report = {}\n",
    "    if name:\n",
    "        report['name'] = name\n",
    "        if verbose:\n",
    "            print(name)\n",
    "    \n",
    "    report[\"RMSE\"] = mean_squared_error(y, y_pred, squared=False)\n",
    "    report[\"MAE\"] = mean_absolute_error(y, y_pred)\n",
    "    report[\"% <2 min\"] = sum(abs(y-y_pred) < 2*60)/len(y)*100\n",
    "    report[\"% <5 min\"] = sum(abs(y-y_pred) < 5*60)/len(y)*100\n",
    "    report[\"% <7 min\"] = sum(abs(y-y_pred) < 7*60)/len(y)*100\n",
    "    report[\"time\"] = str(pd.Timestamp(round(time.time()), unit='s'))\n",
    "    \n",
    "    for kwarg in kwargs:\n",
    "        report[kwarg] = kwargs[kwarg]\n",
    "    \n",
    "    if file is not None:\n",
    "        with open(file, \"a\") as f:\n",
    "            f.write(str(report)+\"\\n\")\n",
    "    if verbose:\n",
    "        print(report)\n",
    "    return(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data is not used separately -> include into training data\n",
    "X_train = pd.concat([X_train, X_val])\n",
    "y_train = pd.concat([y_train, y_val])\n",
    "preprocessor = gen_preprocessor(list(X_train.columns))\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preprocessor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_preprocessor(X_columns):\n",
    "    ColumnTransformations = []\n",
    "    num_cols = []\n",
    "    cat_cols = []\n",
    "    \n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "    for col in X_columns:\n",
    "        if 'circular' in docs[col]['type']:\n",
    "            ColumnTransformations.append(\n",
    "            (\n",
    "                col + '_qcut_' + str(docs[col]['n_bins']),\n",
    "                QuantileTransformer(n_quantiles=docs[col]['n_bins']),\n",
    "                [col]\n",
    "            ))\n",
    "        if 'num' in docs[col]['type']:\n",
    "            num_cols.append(col)\n",
    "        if 'cat' in docs[col]['type']:\n",
    "            cat_cols.append(col)\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    num_trans = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    ColumnTransformations.append((\"num_trans\", num_trans, num_cols))\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    ColumnTransformations.append((\"onehotencode\", OneHotEncoder(handle_unknown='ignore'), cat_cols))\n",
    "\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    return ColumnTransformer(ColumnTransformations, remainder='drop', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SmuBTycfgcly"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 10:24:57.230084658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:stopit:Code block execution exceeded 10 seconds timeout\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/stopit/utils.py\", line 145, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/tpot/decorators.py\", line 57, in time_limited_call\n",
      "    func(*args)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 1314, in fit\n",
      "    mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 1127, in _path_residuals\n",
      "    alphas, coefs, _ = path(X_train, y_train, **path_params)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/sim/miniconda3/envs/venv_tf/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 530, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "stopit.utils.TimeoutException\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/110 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -33741.39694242393\n",
      "\n",
      "Generation 2 - Current best internal CV score: -33741.39694242393\n",
      "\n",
      "Generation 3 - Current best internal CV score: -33510.42535492859\n",
      "\n",
      "Generation 4 - Current best internal CV score: -33426.914543837695\n",
      "\n",
      "Generation 5 - Current best internal CV score: -33173.21287535768\n",
      "\n",
      "Generation 6 - Current best internal CV score: -31666.31390364268\n",
      "\n",
      "Generation 7 - Current best internal CV score: -30436.283321665564\n",
      "\n",
      "Generation 8 - Current best internal CV score: -30202.58603458874\n",
      "\n",
      "Generation 9 - Current best internal CV score: -30202.58603458874\n",
      "\n",
      "Generation 10 - Current best internal CV score: -30202.58603458874\n",
      "\n",
      "Best pipeline: LinearSVR(DecisionTreeRegressor(input_matrix, max_depth=9, min_samples_leaf=6, min_samples_split=6), C=5.0, dual=False, epsilon=0.0001, loss=squared_epsilon_insensitive, tol=1e-05)\n",
      "2021-04-13 10:24:57.230084658\n",
      "0 days 05:48:42.815656424\n",
      "{'RMSE': 166.51795108401382, 'MAE': 121.33314731462242, '% <2 min': 61.00602661256638, '% <5 min': 93.89780615390735, '% <7 min': 97.82007677466834, 'time': '2021-04-13 16:13:40'}\n"
     ]
    }
   ],
   "source": [
    "t0= time.time()\n",
    "print(pd.Timestamp(t0, unit='s'))\n",
    "\n",
    "automl = tpot.TPOTRegressor(\n",
    "    generations=10,\n",
    "    population_size=10,\n",
    "    #config_dict='TPOT light',\n",
    "    verbosity=2,\n",
    "    #_jobs=2,\n",
    ")\n",
    "\n",
    "automl.fit(X_train.toarray(), y_train)\n",
    "y_pred = automl.predict(X_test.toarray())\n",
    "\n",
    "t1= time.time()\n",
    "print(pd.Timestamp(t0, unit='s'))\n",
    "print(pd.Timedelta(t1-t0, unit='s'))\n",
    "      \n",
    "model_eval(y_test, y_pred, name=\"\")\n",
    "\n",
    "automl.export(\"automl_tpot_export.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-tpot_G10_N10_h30, SIMPLE TEST, h0\n",
      "{'name': 'auto-tpot_G10_N10_h30, SIMPLE TEST, h0', 'RMSE': 162.21414004438628, 'MAE': 118.30037508362065, '% <2 min': 61.56960015874591, '% <5 min': 94.68598075205874, '% <7 min': 98.2478420478222, 'time': '2021-04-13 19:26:31', 't': 21600}\n",
      "auto-tpot_G10_N10_h30, SIMPLE TEST, h30\n",
      "{'name': 'auto-tpot_G10_N10_h30, SIMPLE TEST, h30', 'RMSE': 166.51795108401382, 'MAE': 121.33314731462242, '% <2 min': 61.00602661256638, '% <5 min': 93.89780615390735, '% <7 min': 97.82007677466834, 'time': '2021-04-13 19:26:33', 't': 21600}\n",
      "auto-tpot_G10_N10_h30, SIMPLE TEST, h120\n",
      "{'name': 'auto-tpot_G10_N10_h30, SIMPLE TEST, h120', 'RMSE': 213.04641690976166, 'MAE': 155.28512968409746, '% <2 min': 51.37614678899083, '% <5 min': 86.87383291385889, '% <7 min': 94.39798652269221, 'time': '2021-04-13 19:26:38', 't': 21600}\n",
      "auto-tpot_G10_N10_h30, SIMPLE TEST, h180\n",
      "{'name': 'auto-tpot_G10_N10_h30, SIMPLE TEST, h180', 'RMSE': 209.653821332903, 'MAE': 152.67455369511435, '% <2 min': 52.18445149320725, '% <5 min': 87.23143216230774, '% <7 min': 94.67652163504698, 'time': '2021-04-13 19:26:48', 't': 21600}\n"
     ]
    }
   ],
   "source": [
    "for h in [0, 30, 120, 180]:\n",
    "    df = data['processed_dep_h{}'.format(h)]\n",
    "\n",
    "    X_test = df[df['dtype']==\"TEST\"]\n",
    "    X_test.pop(\"dtype\")\n",
    "    y_test = X_test.pop(\"t_taxi\")\n",
    "    \n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    \n",
    "    y_pred = automl.predict(X_test.toarray())\n",
    "    \n",
    "    model_eval(y_test, y_pred, name=\"auto-tpot_G10_N10_h30, SIMPLE TEST, h{}\".format(h),  file=\"model_auto-tpot.txt\", t=6*60*60)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLQC15CgK+xgT+r92bRofy",
   "collapsed_sections": [],
   "name": "auto-sklearn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
