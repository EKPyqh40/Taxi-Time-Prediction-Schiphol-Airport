{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "digital-country",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "casual-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-assembly",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "graduate-february",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['processed_dep_h0', 'processed_dep_h120', 'processed_dep_h180', 'processed_dep_h30', 'raw_dep_h0', 'raw_dep_h120', 'raw_dep_h180', 'raw_dep_h30'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "for path in glob.glob(r\"../../Data/t_taxi/*.csv\"):\n",
    "    data[path.split('\\\\')[-1].split('.')[0]] = pd.read_csv(path)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amber-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Data/t_taxi/csv_docs.json\", \"r\") as f:\n",
    "    docs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-scanning",
   "metadata": {},
   "source": [
    "# Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nutritional-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "def model_eval(y, y_pred, name=None, file=None, verbose=True, **kwargs):\n",
    "    report = {}\n",
    "    if name:\n",
    "        report['name'] = name\n",
    "        if verbose:\n",
    "            print(name)\n",
    "    \n",
    "    report[\"RMSE\"] = mean_squared_error(y, y_pred, squared=False)\n",
    "    report[\"MAE\"] = mean_absolute_error(y, y_pred)\n",
    "    report[\"% <2 min\"] = sum(abs(y-y_pred) < 2*60)/len(y)*100\n",
    "    report[\"% <5 min\"] = sum(abs(y-y_pred) < 5*60)/len(y)*100\n",
    "    report[\"% <7 min\"] = sum(abs(y-y_pred) < 7*60)/len(y)*100\n",
    "    report[\"time\"] = str(pd.Timestamp(round(time.time()), unit='s'))\n",
    "    \n",
    "    for kwarg in kwargs:\n",
    "        report[kwarg] = kwargs[kwarg]\n",
    "    \n",
    "    if file is not None:\n",
    "        with open(file, \"a\") as f:\n",
    "            f.write(str(report)+\"\\n\")\n",
    "    if verbose:\n",
    "        print(report)\n",
    "    return(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-prague",
   "metadata": {},
   "source": [
    "# Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "light-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_preprocessor(X_columns):\n",
    "    ColumnTransformations = []\n",
    "    num_cols = []\n",
    "    cat_cols = []\n",
    "    \n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "    for col in X_columns:\n",
    "        if 'circular' in docs[col]['type']:\n",
    "            ColumnTransformations.append(\n",
    "            (\n",
    "                col + '_qcut_' + str(docs[col]['n_bins']),\n",
    "                QuantileTransformer(n_quantiles=docs[col]['n_bins']),\n",
    "                [col]\n",
    "            ))\n",
    "        if 'num' in docs[col]['type']:\n",
    "            num_cols.append(col)\n",
    "        if 'cat' in docs[col]['type']:\n",
    "            cat_cols.append(col)\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    num_trans = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    ColumnTransformations.append((\"num_trans\", num_trans, num_cols))\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    ColumnTransformations.append((\"onehotencode\", OneHotEncoder(handle_unknown='ignore'), cat_cols))\n",
    "\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    return ColumnTransformer(ColumnTransformations, remainder='drop', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-rebound",
   "metadata": {},
   "source": [
    "# Data Selection and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "immune-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-e4d2a3ab9c9d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['center_crossing'][(df['center_crossing']=='-')|(df['trwy']!='36L')] = np.nan\n"
     ]
    }
   ],
   "source": [
    "h = 30\n",
    "df = data['raw_dep_h{}'.format(h)].copy()\n",
    "df['center_crossing'][(df['center_crossing']=='-')|(df['trwy']!='36L')] = np.nan\n",
    "df['trwy_ext'] = df['trwy'] + (\"_\" + df['center_crossing']).fillna('')\n",
    "df.sort_values('t_predict', inplace=True)\n",
    "\n",
    "train = pd.DataFrame(index=df.iloc[:int(df.shape[0]*.7)].index)\n",
    "train['dtype'] = \"TRAIN\"\n",
    "val = pd.DataFrame(index=df.iloc[int(df.shape[0]*.7):int(df.shape[0]*0.85)].index)\n",
    "val['dtype'] = \"VALIDATE\"\n",
    "test = pd.DataFrame(index=df.iloc[int(df.shape[0]*0.85):].index)\n",
    "test['dtype'] = \"TEST\"\n",
    "df = pd.concat([df, pd.concat([train, val, test])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consistent-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols_circ = []\n",
    "X_cols_num = []\n",
    "X_cols_cat = []\n",
    "astype_dict = {}\n",
    "for col in df.columns:\n",
    "    if \"dtype\" == col:\n",
    "        continue\n",
    "    if 'circular' in docs[col]['type']:\n",
    "        X_cols_circ.append(col)\n",
    "        X_cols_cat.append(col)\n",
    "        astype_dict[col] = 'category'\n",
    "    elif \"num\" in docs[col]['type']:\n",
    "        X_cols_num.append(col)\n",
    "        astype_dict[col] = np.float64\n",
    "    elif \"cat\" in docs[col]['type']:\n",
    "        X_cols_cat.append(col)\n",
    "        astype_dict[col] = \"category\"\n",
    "    \n",
    "\n",
    "X_cols = X_cols_cat + X_cols_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df['dtype']=='TRAIN']\n",
    "y_train = X_train.pop('t_taxi')\n",
    "\n",
    "X_val = df[df['dtype']=='VALIDATE']\n",
    "y_val = X_val.pop('t_taxi')\n",
    "\n",
    "X_test = df[df['dtype']=='TEST']\n",
    "y_test = X_test.pop('t_taxi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-apparatus",
   "metadata": {},
   "source": [
    "# Linear Model, No Performance Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recognized-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_pf_train\n",
      "{'name': 'no_pf_train', 'RMSE': 183.6191804345149, 'MAE': 124.38923499757205, '% <2 min': 61.56967262023151, '% <5 min': 92.66478380206054, '% <7 min': 97.1677473248737, 'time': '2021-04-29 10:43:44'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "alpha = .4\n",
    "epsilon = 1.\n",
    "\n",
    "regr = HuberRegressor(\n",
    "    max_iter=10000,\n",
    "    alpha=alpha,\n",
    "    epsilon=epsilon,\n",
    ")\n",
    "\n",
    "X_cols_sel = [\n",
    "    'actype',\n",
    "    'depgnr',\n",
    "    'n_dep',\n",
    "    'dew',\n",
    "    'lightning',\n",
    "    'rvr5000_2000',\n",
    "    'plr1',\n",
    "    'plr2',\n",
    "    'local_mod',\n",
    "    'trwy_ext',\n",
    "]\n",
    "\n",
    "t0 = time.time()\n",
    "model = Pipeline(steps=[(\"preprocessor\", gen_preprocessor(X_cols_sel)),\n",
    "                       (\"regressor\", regr)])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "no_fs_score = model_eval(\n",
    "    y_val, \n",
    "    y_val_pred,\n",
    "    name='no_pf_train',\n",
    ")['% <2 min']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-possession",
   "metadata": {},
   "source": [
    "# Performance Feedback\n",
    "\n",
    "## Performance Feedback PostgreSQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indoor-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "X_val_pf = pd.concat([X_train, X_val])[['t_taxi_end', 't_predict', 'dtype']]\n",
    "X_val_pf['t_taxi_end'] = pd.to_datetime(X_val_pf['t_taxi_end'])\n",
    "X_val_pf['t_predict'] = pd.to_datetime(X_val_pf['t_predict'])\n",
    "X_val_pf['error'] = pd.concat([y_train, y_val]) - np.hstack([y_train_pred, y_val_pred])\n",
    "\n",
    "table = 'lr_pf_data_val'\n",
    "\n",
    "POSTGRES_ADDRESS = 'localhost'\n",
    "POSTGRES_USERNAME = 'postgres' \n",
    "POSTGRES_PASSWORD = 'jonp8UMs8qDV4jEcwOC0'\n",
    "POSTGRES_DBNAME = 'thesis'\n",
    "\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}/{dbname}' \n",
    "                .format(username=POSTGRES_USERNAME,\n",
    "                        password=POSTGRES_PASSWORD,\n",
    "                        ipaddress=POSTGRES_ADDRESS,\n",
    "                        dbname=POSTGRES_DBNAME))\n",
    "\n",
    "cnx = create_engine(postgres_str)\n",
    "\n",
    "X_val_pf.to_sql(table, cnx, if_exists='replace')\n",
    "\n",
    "with cnx.connect() as con:\n",
    "    for col in ['t_taxi_end', 't_predict', 'dtype']:\n",
    "        con.execute(\"CREATE INDEX ix_{}_{} ON {} ({})\".format(table, col, table, col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-motivation",
   "metadata": {},
   "source": [
    "## Performance Feedback Tuning (lookback_min, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "clean-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 184.7819630215103, 'MAE': 124.8550352013978, '% <2 min': 61.69298699232269, '% <5 min': 92.4181550578782, '% <7 min': 97.05238871872389, 'time': '2021-04-29 10:49:13'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 184.7819630215103,\n",
       " 'MAE': 124.8550352013978,\n",
       " '% <2 min': 61.69298699232269,\n",
       " '% <5 min': 92.4181550578782,\n",
       " '% <7 min': 97.05238871872389,\n",
       " 'time': '2021-04-29 10:49:13'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = {\n",
    "    \"value\": no_fs_score,\n",
    "    \"lookback_min\": 0,\n",
    "    \"factor\": 0,\n",
    "}\n",
    "\n",
    "dtype = 'VALIDATE'\n",
    "\n",
    "def avg_lookback_error(interval_m, table,  dtype):\n",
    "    query = \"\"\"\n",
    "        SELECT a.index, AVG(b.error)\n",
    "        FROM\n",
    "            {table} AS a\n",
    "            LEFT JOIN\n",
    "            {table} AS b\n",
    "            ON (a.t_predict > b.t_taxi_end) AND (a.t_predict - interval '{interval_m} minutes' < b.t_taxi_end)\n",
    "        WHERE a.dtype='{dtype}'\n",
    "        GROUP BY a.index;\n",
    "    \"\"\".format(table=table, interval_m=interval_m, dtype=dtype)\n",
    "    return pd.read_sql_query(query, cnx, index_col='index').fillna(0).values[:,0]\n",
    "\n",
    "short_term_correction  = 0.08 * avg_lookback_error(55.28157368274357, table, dtype)\n",
    "long_term_correction = 0.14 * avg_lookback_error(10147.315800050748, table, dtype)\n",
    "\n",
    "for i, interval_m in enumerate(np.logspace(np.log10(30), np.log10(21*24*60), num=20)):\n",
    "    print(i, interval_m)    \n",
    "\n",
    "    new_correction = avg_lookback_error(interval_m, table, dtype)\n",
    "    \n",
    "    for factor in np.linspace(0,1,101):\n",
    "#         y_val_pf_pred = (y_val_pred - factor * avg_td_error['avg']).to_numpy()\n",
    "\n",
    "        y_val_pf_pred = (y_val_pred - short_term_correction - long_term_correction - factor * new_correction)\n",
    "\n",
    "        report = model_eval(y_val, y_val_pf_pred, verbose=False)\n",
    "        if report['% <2 min'] > best['value']:\n",
    "            print(\"new optimium\", interval_m, factor, report['% <2 min'])\n",
    "            best = {\n",
    "                \"value\": report['% <2 min'],\n",
    "                \"lookback_min\": interval_m,\n",
    "                \"factor\": factor\n",
    "            }\n",
    "\n",
    "model_eval(y_val, (y_val_pred - short_term_correction - long_term_correction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-panama",
   "metadata": {},
   "source": [
    "# Table: Performance Feedback Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "collect-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  \\% <2 min &     MAE &    RMSE &  \\% <5 min &  \\% <7 min \\\\\n",
      "\\midrule\n",
      "0 &     61.57 &  124.39 &  183.62 &     92.66 &     97.17 \\\\\n",
      "1 &     61.69 &  124.86 &  184.78 &     92.42 &     97.05 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame([\n",
    "    {\n",
    "        'name': 'no_pf_train', \n",
    "        'RMSE': 183.6191804345149, \n",
    "        'MAE': 124.38923499757205, \n",
    "        '% <2 min': 61.56967262023151, \n",
    "        '% <5 min': 92.66478380206054, \n",
    "        '% <7 min': 97.1677473248737, \n",
    "        'time': '2021-04-29 10:43:44'\n",
    "    },\n",
    "    {\n",
    "        'RMSE': 184.7819630215103,\n",
    "        'MAE': 124.8550352013978,\n",
    "        '% <2 min': 61.69298699232269,\n",
    "        '% <5 min': 92.4181550578782,\n",
    "        '% <7 min': 97.05238871872389,\n",
    "        'time': '2021-04-29 10:49:13'\n",
    "    }  \n",
    "])\n",
    "print(out[[\"% <2 min\", \"MAE\", \"RMSE\", \"% <5 min\", \"% <7 min\"]].round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-extra",
   "metadata": {},
   "source": [
    "# Performance Feedback Test Data\n",
    "\n",
    "## No Performance Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "married-mississippi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 172.42617267715704, 'MAE': 123.5536063902857, '% <2 min': 60.91055552240587, '% <5 min': 92.78198778765639, '% <7 min': 97.44813731925134, 'time': '2021-04-29 10:49:48'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 172.42617267715704,\n",
       " 'MAE': 123.5536063902857,\n",
       " '% <2 min': 60.91055552240587,\n",
       " '% <5 min': 92.78198778765639,\n",
       " '% <7 min': 97.44813731925134,\n",
       " 'time': '2021-04-29 10:49:48'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "alpha = .4\n",
    "epsilon = 1.\n",
    "\n",
    "regr = HuberRegressor(\n",
    "    max_iter=10000,\n",
    "    alpha=alpha,\n",
    "    epsilon=epsilon,\n",
    ")\n",
    "\n",
    "X_cols_sel = [\n",
    "    'actype',\n",
    "    'depgnr',\n",
    "    'n_dep',\n",
    "    'dew',\n",
    "    'lightning',\n",
    "    'rvr5000_2000',\n",
    "    'plr1',\n",
    "    'plr2',\n",
    "    'local_mod',\n",
    "    'trwy_ext',\n",
    "]\n",
    "\n",
    "t0 = time.time()\n",
    "model = Pipeline(steps=[(\"preprocessor\", gen_preprocessor(X_cols_sel)),\n",
    "                       (\"regressor\", regr)])\n",
    "\n",
    "model.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "model_eval(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-presence",
   "metadata": {},
   "source": [
    "## Calculate and Evaluate Performance Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dedicated-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"lr_pf_data_test\"\n",
    "dtype = \"TEST\"\n",
    "\n",
    "X_test_pf = pd.concat([X_train, X_val, X_test])[['t_taxi_end', 't_predict', 'dtype']]\n",
    "X_test_pf['t_taxi_end'] = pd.to_datetime(X_test_pf['t_taxi_end'])\n",
    "X_test_pf['t_predict'] = pd.to_datetime(X_test_pf['t_predict'])\n",
    "X_test_pf['error'] = pd.concat([y_train, y_val, y_test]) - np.hstack([y_train_pred, y_val_pred, y_test_pred])\n",
    "\n",
    "X_test_pf.to_sql(table, cnx, if_exists='replace')\n",
    "\n",
    "with cnx.connect() as con:\n",
    "    for col in ['t_taxi_end', 't_predict', 'dtype']:\n",
    "        con.execute(\"CREATE INDEX ix_{}_{} ON {} ({})\".format(table, col, table, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "framed-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 173.55815545922746, 'MAE': 123.99405039968248, '% <2 min': 60.926467370765955, '% <5 min': 92.60099051256041, '% <7 min': 97.33874336177576, 'time': '2021-04-29 10:51:30'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 173.55815545922746,\n",
       " 'MAE': 123.99405039968248,\n",
       " '% <2 min': 60.926467370765955,\n",
       " '% <5 min': 92.60099051256041,\n",
       " '% <7 min': 97.33874336177576,\n",
       " 'time': '2021-04-29 10:51:30'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_term_correction  = 0.08 * avg_lookback_error(55.28157368274357, table, dtype)\n",
    "long_term_correction = 0.14 * avg_lookback_error(10147.315800050748, table, dtype)\n",
    "y_test_pf_pred = (y_test_pred - short_term_correction - long_term_correction)\n",
    "\n",
    "model_eval(y_test, y_test_pf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-chess",
   "metadata": {},
   "source": [
    "# Table: Performance Feedback Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rental-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  \\% <2 min &     MAE &    RMSE &  \\% <5 min &  \\% <7 min \\\\\n",
      "\\midrule\n",
      "0 &     60.91 &  123.55 &  172.43 &     92.78 &     97.45 \\\\\n",
      "1 &     60.93 &  123.99 &  173.56 &     92.60 &     97.34 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame([\n",
    "    {\n",
    "        'RMSE': 172.42617267715704,\n",
    "        'MAE': 123.5536063902857,\n",
    "        '% <2 min': 60.91055552240587,\n",
    "        '% <5 min': 92.78198778765639,\n",
    "        '% <7 min': 97.44813731925134,\n",
    "        'time': '2021-04-29 10:49:48'\n",
    "    },\n",
    "    {\n",
    "        'RMSE': 173.55815545922746,\n",
    "        'MAE': 123.99405039968248,\n",
    "        '% <2 min': 60.926467370765955,\n",
    "        '% <5 min': 92.60099051256041,\n",
    "        '% <7 min': 97.33874336177576,\n",
    "        'time': '2021-04-29 10:51:30'\n",
    "    }  \n",
    "])\n",
    "print(out[[\"% <2 min\", \"MAE\", \"RMSE\", \"% <5 min\", \"% <7 min\"]].round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-boston",
   "metadata": {},
   "source": [
    "# Validate (Algorithm not valdiation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "danish-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 183.6162753471294, 'MAE': 124.38756391693973, '% <2 min': 61.56967262023151, '% <5 min': 92.66478380206054, '% <7 min': 97.1677473248737, 'time': '2021-04-29 10:51:56'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 183.6162753471294,\n",
       " 'MAE': 124.38756391693973,\n",
       " '% <2 min': 61.56967262023151,\n",
       " '% <5 min': 92.66478380206054,\n",
       " '% <7 min': 97.1677473248737,\n",
       " 'time': '2021-04-29 10:51:56'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "alpha = .4\n",
    "epsilon = 1.\n",
    "\n",
    "regr = HuberRegressor(\n",
    "    max_iter=10000,\n",
    "    alpha=alpha,\n",
    "    epsilon=epsilon,\n",
    ")\n",
    "\n",
    "X_cols_sel = [\n",
    "    'actype',\n",
    "    'depgnr',\n",
    "    'n_dep',\n",
    "    'dew',\n",
    "    'lightning',\n",
    "    'rvr5000_2000',\n",
    "    'plr1',\n",
    "    'plr2',\n",
    "    'local_mod',\n",
    "    'trwy_ext',\n",
    "]\n",
    "\n",
    "t0 = time.time()\n",
    "model = Pipeline(steps=[(\"preprocessor\", gen_preprocessor(X_cols_sel)),\n",
    "                       (\"regressor\", regr)])\n",
    "\n",
    "model.fit(pd.concat([X_train]), pd.concat([y_train]))\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "model_eval(y_val, y_val_pred)\n",
    "# 55972791280481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "metallic-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"lr_pf_data_val\"\n",
    "dtype = \"VALIDATE\"\n",
    "\n",
    "X_val_pf = pd.concat([X_train, X_val])[['t_taxi_end', 't_predict', 'dtype']]\n",
    "X_val_pf['t_taxi_end'] = pd.to_datetime(X_val_pf['t_taxi_end'])\n",
    "X_val_pf['t_predict'] = pd.to_datetime(X_val_pf['t_predict'])\n",
    "X_val_pf['error'] = pd.concat([y_train, y_val]) - np.hstack([y_train_pred, y_val_pred])\n",
    "\n",
    "X_val_pf.to_sql(table, cnx, if_exists='replace')\n",
    "\n",
    "with cnx.connect() as con:\n",
    "    for col in ['t_taxi_end', 't_predict', 'dtype']:\n",
    "        con.execute(\"CREATE INDEX ix_{}_{} ON {} ({})\".format(table, col, table, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-metabolism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 184.77881790437058, 'MAE': 124.85329489674461, '% <2 min': 61.690998050837344, '% <5 min': 92.41616611639284, '% <7 min': 97.05437766020924, 'time': '2021-04-29 10:53:36'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 184.77881790437058,\n",
       " 'MAE': 124.85329489674461,\n",
       " '% <2 min': 61.690998050837344,\n",
       " '% <5 min': 92.41616611639284,\n",
       " '% <7 min': 97.05437766020924,\n",
       " 'time': '2021-04-29 10:53:36'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_term_correction  = 0.08 * avg_lookback_error(55.28157368274357, table, dtype)\n",
    "long_term_correction = 0.14 * avg_lookback_error(10147.315800050748, table, dtype)\n",
    "y_val_pf_pred = (y_val_pred - short_term_correction - long_term_correction)\n",
    "\n",
    "model_eval(y_val, y_val_pf_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
