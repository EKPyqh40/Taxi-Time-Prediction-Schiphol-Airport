{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automated-complaint",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eligible-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-canon",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powered-seafood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['processed_dep_h0', 'processed_dep_h120', 'processed_dep_h180', 'processed_dep_h30'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "for path in glob.glob(r\"../Data/t_taxi/*.csv\"):\n",
    "    data[path.split('\\\\')[-1].split('.')[0]] = pd.read_csv(path)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-indonesia",
   "metadata": {},
   "source": [
    "# Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "permanent-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "def model_eval(y, y_pred, name=None, file=None, verbose=True, **kwargs):\n",
    "    report = {}\n",
    "    if name:\n",
    "        report['name'] = name\n",
    "        if verbose:\n",
    "            print(name)\n",
    "    \n",
    "    report[\"RMSE\"] = mean_squared_error(y, y_pred, squared=False)\n",
    "    report[\"MAE\"] = mean_absolute_error(y, y_pred)\n",
    "    report[\"% <2 min\"] = sum(abs(y-y_pred) < 2*60)/len(y)*100\n",
    "    report[\"% <5 min\"] = sum(abs(y-y_pred) < 5*60)/len(y)*100\n",
    "    report[\"% <7 min\"] = sum(abs(y-y_pred) < 7*60)/len(y)*100\n",
    "    report[\"time\"] = round(time.time())\n",
    "    \n",
    "    for kwarg in kwargs:\n",
    "        report[kwarg] = kwargs[kwarg]\n",
    "    \n",
    "    if file is not None:\n",
    "        with open(file, \"a\") as f:\n",
    "            f.write(str(report)+\"\\n\")\n",
    "    if verbose:\n",
    "        print(report)\n",
    "    return(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-unemployment",
   "metadata": {},
   "source": [
    "# Mean Taxi Time Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lesbian-modeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_avg_h0\n",
      "{'name': 'model_avg_h0', 'RMSE': 262.7578933186738, 'MAE': 205.94839328000802, '% <2 min': 34.55104673082647, '% <5 min': 77.39061414822899, '% <7 min': 91.57456096835004, 'time': 1618412291, 'dataset_train': 'processed_dep_h0', 'dataset_test': 'processed_dep_h0', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n",
      "model_avg_h30\n",
      "{'name': 'model_avg_h30', 'RMSE': 262.742998949917, 'MAE': 205.91180176808544, '% <2 min': 34.55104673082647, '% <5 min': 77.39061414822899, '% <7 min': 91.57456096835004, 'time': 1618412291, 'dataset_train': 'processed_dep_h30', 'dataset_eval': 'processed_dep_h0', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n",
      "model_avg_h30\n",
      "{'name': 'model_avg_h30', 'RMSE': 262.16427367945937, 'MAE': 205.84238223873606, '% <2 min': 34.55257871392486, '% <5 min': 77.38727449927401, '% <7 min': 91.57865425542494, 'time': 1618412291, 'dataset_train': 'processed_dep_h30', 'dataset_test': 'processed_dep_h30', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n",
      "model_avg_h30\n",
      "{'name': 'model_avg_h30', 'RMSE': 262.16427367945937, 'MAE': 205.84238223873606, '% <2 min': 34.55257871392486, '% <5 min': 77.38727449927401, '% <7 min': 91.57865425542494, 'time': 1618412291, 'dataset_train': 'processed_dep_h30', 'dataset_eval': 'processed_dep_h30', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n",
      "model_avg_h120\n",
      "{'name': 'model_avg_h120', 'RMSE': 262.06735387492444, 'MAE': 205.5485585057264, '% <2 min': 34.651294958187876, '% <5 min': 77.56961922546076, '% <7 min': 91.6517820897946, 'time': 1618412291, 'dataset_train': 'processed_dep_h120', 'dataset_test': 'processed_dep_h120', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n",
      "model_avg_h30\n",
      "{'name': 'model_avg_h30', 'RMSE': 262.23573315411153, 'MAE': 205.960337909025, '% <2 min': 34.47268003572299, '% <5 min': 77.3788260128278, '% <7 min': 91.62133636437444, 'time': 1618412291, 'dataset_train': 'processed_dep_h30', 'dataset_eval': 'processed_dep_h120', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n",
      "model_avg_h180\n",
      "{'name': 'model_avg_h180', 'RMSE': 252.98078445650387, 'MAE': 198.3722095115586, '% <2 min': 36.01053324555629, '% <5 min': 79.27763480758873, '% <7 min': 92.51002453767431, 'time': 1618412292, 'dataset_train': 'processed_dep_h180', 'dataset_test': 'processed_dep_h180', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n",
      "model_avg_h30\n",
      "{'name': 'model_avg_h30', 'RMSE': 254.02759589853267, 'MAE': 200.45382606706042, '% <2 min': 35.29235741217308, '% <5 min': 78.64025375546113, '% <7 min': 92.49506254114549, 'time': 1618412292, 'dataset_train': 'processed_dep_h30', 'dataset_eval': 'processed_dep_h180', 'model_type': 'Average', 'eval_type': 'SIMPLE_TEST'}\n"
     ]
    }
   ],
   "source": [
    "avg_h30 = data['processed_dep_h30']\n",
    "avg_h30 = avg_h30[avg_h30['dtype'].isin(['TRAIN', \"VALIDATE\"])]['t_taxi'].mean()\n",
    "\n",
    "for h in [0, 30, 120, 180]:\n",
    "    \n",
    "    # This is ugly, apologies!\n",
    "    df = data['processed_dep_h{}'.format(h)]\n",
    "    \n",
    "    X_train = df[df['dtype']==\"TRAIN\"]\n",
    "    X_train.pop(\"dtype\")\n",
    "    y_train = X_train.pop(\"t_taxi\")\n",
    "    \n",
    "    X_val = df[df['dtype']==\"VALIDATE\"]\n",
    "    X_val.pop(\"dtype\")\n",
    "    y_val = X_val.pop(\"t_taxi\")\n",
    "    \n",
    "    X_test = df[df['dtype']==\"TEST\"]\n",
    "    X_test.pop(\"dtype\")\n",
    "    y_test = X_test.pop(\"t_taxi\")\n",
    "    \n",
    "    avg_h = pd.concat([y_train, y_val]).mean()\n",
    "    \n",
    "    model_eval(\n",
    "        y_test, \n",
    "        np.ones(len(y_test))*avg_h, \n",
    "        name=\"model_avg_h{}\".format(h), \n",
    "        file=\"./results/model_average.results\",\n",
    "        dataset_train=\"processed_dep_h{}\".format(h),\n",
    "        dataset_test=\"processed_dep_h{}\".format(h),\n",
    "        model_type=\"Average\",\n",
    "        eval_type=\"SIMPLE_TEST\",\n",
    "    )\n",
    "    model_eval(\n",
    "        y_test, \n",
    "        np.ones(len(y_test))*avg_h30, \n",
    "        name=\"model_avg_h30\",\n",
    "        file=\"./results/model_average.results\",\n",
    "        dataset_train=\"processed_dep_h30\",\n",
    "        dataset_test=\"processed_dep_h{}\".format(h),\n",
    "        model_type=\"Average\",\n",
    "        eval_type = \"SIMPLE_TEST\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
